import pandas as pd
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
import re
import time


class NewsScrap:

    def __init__(self):
        self.request_timeout = 120
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}

        self.session = requests.Session()
        retries = Retry(total=5, backoff_factor=0.5, status_forcelist=[502, 503, 504])
        self.session.mount('http://', HTTPAdapter(max_retries=retries))

    def __request(self, url):
        try:
            response = self.session.get(url, timeout=self.request_timeout, headers=self.headers)
            response.raise_for_status()
            content = response.content.decode('utf-8')
            return content
        except Exception as e:
            raise

    def get_news(soup):
        list1 = []
        cats = ['News', ' News', 'Analysis', 'Sponsored', 'Market Update']
        for cat in cats:
            for n in [i for i, e in enumerate(soup) if e == cat]:
                list1.append((soup[n:n + 6]))

        news = pd.DataFrame(list1)
        news.drop([3], axis=1, inplace=True)
        news.columns = ['category', 'heading', 'news', 'author', 'time']
        news['category'] = news['category'].apply(lambda x: x.replace(' News', 'News'))

        def get_date(x):
            now = datetime.now()
            num = int(re.findall('\d+', x)[0])
            if "MINUTES" in x:
                return (now - timedelta(minutes=num)).strftime(format='%Y-%m-%d %H:%M:%S')
            else:
                return (now - timedelta(hours=num)).strftime(format='%Y-%m-%d %H:%M:%S')

        news['time'] = news['time'].apply(get_date)
        news['source'] = ['CoinTelegraph'] * len(news)
        return news

    def Cointelegraph_News(self):
        url = 'https://cointelegraph.com/'
        content = self.__request(url)
        soup = BeautifulSoup(content, 'html.parser')
        for text in soup.find_all('div', attrs={'class': 'main-page'}):
            b = text.text.split('  ')
            c = [n.replace('Subscribe', '') for n in b if len(n) > 2]
        news = NewsScrap.get_news(c)
        news.sort_values('time', ascending=False, inplace=True)
        news.reset_index(drop=True, inplace=True)
        return news

    def CoinDesk_News(self):
        url = "https://www.coindesk.com/"
        content = self.__request(url)
        soup = BeautifulSoup(content, 'html.parser')

        l1 = [text['href'] for text in soup.find_all('a', attrs={'class': 'stream-article'}, href=True)]
        cat = []
        heads = []
        newss = []
        authors = []
        times = []
        for link in l1:
            content = requests.get(link).content
            soup1 = BeautifulSoup(content, 'html.parser')
            list1 = [text for text in soup1.find_all('article', attrs={'class': 'coindesk-article'})]
            list1 = [text for text in list1[0].text.replace('\n', ' ').split('  ') if
                     len(text) > 1 and 'Updated' not in text]
            cat.append(list1[3])
            heads.append(list1[0])
            newss.append(list1[4])
            authors.append(list1[1])
            times.append(list1[2][:-3])
        df = pd.DataFrame(data=[cat, heads, newss, authors, times]).T
        df.columns = ['category', 'heading', 'news', 'author', 'time']
        df['category'] = df['category'].apply(lambda x: x.replace(' news', 'news'))

        df['source'] = ['CoinDesk'] * len(df)

        df['time'] = pd.to_datetime(df['time'].apply(lambda x: ' '.join(x.split('at'))))
        df.sort_values('time', ascending=False, inplace=True)
        df.reset_index(drop=True, inplace=True)

        return df

    def cryptonewsz(self):
        url = 'https://www.cryptonewsz.com/category/cryptocurrency/'
        content = self.__request(url)
        soup = BeautifulSoup(content, 'html.parser')
        links = [text['href'] for text in soup.find_all('a', attrs={'class': "post-thumb"})]
        author = []
        heading = []
        time1 = []
        news1 = []
        links = set(links)
        for link in links:
            content = requests.get(link).content
            soup1 = BeautifulSoup(content, 'html.parser')
            aa = [text.text for text in soup1.find_all('div', attrs={'class': 'entry-content'})]
            news1.append(' '.join(aa[0].split('  ')))

            aa = [text.div.text for text in soup1.find_all('article', attrs={'class': 'container-wrapper'})]

            aa = [text for text in aa[0].split('  ') if len(text) > 2]

            heading.append(aa[0])
            author.append(aa[1])
            time1.append(aa[-1])
            time.sleep(1)

        cats = ['news'] * len(author)

        data1 = pd.DataFrame(data=[cats, heading, news1, author, time1]).T
        data1.columns = ['category', 'heading', 'news', 'author', 'time']

        def get_cat(x):
            if x.startswith('Crypto'):
                return 'Cryptocurrency'
            elif x.startswith('Blockchain'):
                return 'Blockchain'
            else:
                return 'Price Analysis'

        data1['category'] = data1['heading'].apply(get_cat)
        data1['heading'] = data1.apply(lambda x: x['heading'].replace(x['category'], ''), axis=1)

        data1['time'] = data1['time'].apply(lambda x: x.split('ago')[0])

        def get_date(x):
            now = datetime.now()
            num = int(re.findall('\d+', x)[0])
            if "hour" in x:
                return (now - timedelta(hours=num)).strftime(format='%Y-%m-%d %H:%M:%S')
            elif 'day' in x:
                return (now - timedelta(days=num)).strftime(format='%Y-%m-%d %H:%M:%S')
            else:
                return (now - timedelta(minutes=num)).strftime(format='%Y-%m-%d %H:%M:%S')

        data1['time'] = data1['time'].apply(get_date)

        data1.sort_values('time', ascending=False, inplace=True)
        data1.reset_index(drop=True, inplace=True)
        data1['source'] = ['cryptonewsz'] * len(data1)
        return data1

    def get_all_news(self):
        print('Getting news from CoinDesk!!')
        n1 = NewsScrap.CoinDesk_News(self)
        print('Getting news from Cointelegraph!!')
        n2 = NewsScrap.Cointelegraph_News(self)
        print('Getting news from cryptonewsz!! This will take 1-2 mintues. ðŸ˜‰')
        n3 = NewsScrap.cryptonewsz(self)
        all_news = pd.concat([n1, n2, n3], axis=0)
        all_news.reset_index(drop=True, inplace=True)
        return all_news


